{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyMSl7V1+dnyRRH5huZVxiJG",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/IhuanGunawan/MangaGAN/blob/master/VirtualLabelling_sample.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import shutil\n",
        "%pip install ml-collections"
      ],
      "metadata": {
        "id": "2xZDGF6ioPnO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "53eafc83-18f5-4564-f53a-1eb1a48c1d4f"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting ml-collections\n",
            "  Downloading ml_collections-0.1.1.tar.gz (77 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/77.9 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━\u001b[0m \u001b[32m71.7/77.9 kB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.9/77.9 kB\u001b[0m \u001b[31m1.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: absl-py in /usr/local/lib/python3.10/dist-packages (from ml-collections) (1.4.0)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.10/dist-packages (from ml-collections) (6.0.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from ml-collections) (1.16.0)\n",
            "Requirement already satisfied: contextlib2 in /usr/local/lib/python3.10/dist-packages (from ml-collections) (21.6.0)\n",
            "Building wheels for collected packages: ml-collections\n",
            "  Building wheel for ml-collections (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for ml-collections: filename=ml_collections-0.1.1-py3-none-any.whl size=94506 sha256=419c12a0ef86196e4a60ae40d5f57fae9c363532e93626ec977924cecfda5d47\n",
            "  Stored in directory: /root/.cache/pip/wheels/7b/89/c9/a9b87790789e94aadcfc393c283e3ecd5ab916aed0a31be8fe\n",
            "Successfully built ml-collections\n",
            "Installing collected packages: ml-collections\n",
            "Successfully installed ml-collections-0.1.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# clone virtual labelling repository\n",
        "if not os.path.exists('./VirtualLabelling'):\n",
        "    !git clone https://github.com/CancerSystemsMicroscopyLab/VirtualLabelling.git\n",
        "\n",
        "    # move cloned proj to root so that modules can be imported\n",
        "    source = './VirtualLabelling/'\n",
        "    destination = './'\n",
        "\n",
        "    for file in os.listdir(source) :\n",
        "        file_name = os.path.join(source, file)\n",
        "        shutil.move(file_name, destination)\n",
        "\n",
        "    # get and store pretrained model from google cloud\n",
        "    pretrain_dir = './model/vit_checkpoint/imagenet21k'\n",
        "    os.makedirs(pretrain_dir)\n",
        "    !wget https://storage.googleapis.com/vit_models/imagenet21k/R50+ViT-B_16.npz\n",
        "    shutil.move('./R50+ViT-B_16.npz', pretrain_dir)\n"
      ],
      "metadata": {
        "id": "roDRMmXwoWJl",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "890c1c33-9206-4566-8d4e-11b55964f9bf"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'VirtualLabelling'...\n",
            "remote: Enumerating objects: 78, done.\u001b[K\n",
            "remote: Counting objects: 100% (9/9), done.\u001b[K\n",
            "remote: Compressing objects: 100% (9/9), done.\u001b[K\n",
            "remote: Total 78 (delta 3), reused 0 (delta 0), pack-reused 69\u001b[K\n",
            "Receiving objects: 100% (78/78), 1.63 MiB | 17.62 MiB/s, done.\n",
            "Resolving deltas: 100% (5/5), done.\n",
            "--2024-04-15 03:11:36--  https://storage.googleapis.com/vit_models/imagenet21k/R50+ViT-B_16.npz\n",
            "Resolving storage.googleapis.com (storage.googleapis.com)... 108.177.98.207, 74.125.197.207, 74.125.135.207, ...\n",
            "Connecting to storage.googleapis.com (storage.googleapis.com)|108.177.98.207|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 461217452 (440M) [application/octet-stream]\n",
            "Saving to: ‘R50+ViT-B_16.npz’\n",
            "\n",
            "R50+ViT-B_16.npz    100%[===================>] 439.85M  27.0MB/s    in 18s     \n",
            "\n",
            "2024-04-15 03:11:54 (25.1 MB/s) - ‘R50+ViT-B_16.npz’ saved [461217452/461217452]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# upload dataset to data folder. Each marker should be placed in a separate folder, as done in the data_examples folder.\n",
        "os.makedirs('./data', exist_ok=True)"
      ],
      "metadata": {
        "id": "1jID9j4-tVlH"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from train_model import train_resvit_vl\n",
        "from apply_model import apply_model\n",
        "\n",
        "dataroot = './data_example' # replace with a path to your images\n",
        "inputs = ['TD', 'DAPI'] # folders within the dataroot folder that will be used as inputs\n",
        "target = 'Fibrillarin' # target\n",
        "\n",
        "exp_name = train_resvit_vl(dataroot, inputs, target) # trains a model for images which there are target images\n",
        "\n",
        "apply_model(dataroot, exp_name) # makes predictions for all images (with and without a target image)\n",
        "\n",
        "# results folder should contain trained model and virtual labels"
      ],
      "metadata": {
        "id": "gRDsOa-oxDsy",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bb067af5-9796-4edd-92e1-d1e40f04b065"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "#training images = 7\n",
            "20240415-031222 TD_DAPI-Fibrillarin/art_pretain\n",
            "resvit_one\n",
            "initialization method [normal]\n",
            "model [ResViT_model] was created\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/content/models/networks.py:19: UserWarning: nn.init.normal is now deprecated in favor of nn.init.normal_.\n",
            "  init.normal(m.weight.data, 0.0, 0.02)\n",
            "/content/models/networks.py:23: UserWarning: nn.init.normal is now deprecated in favor of nn.init.normal_.\n",
            "  init.normal(m.weight.data, 1.0, 0.02)\n",
            "/content/models/networks.py:24: UserWarning: nn.init.constant is now deprecated in favor of nn.init.constant_.\n",
            "  init.constant(m.bias.data, 0.0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "saving the latest model (epoch 1, total_steps 7)\n",
            "End of epoch 1 / 100 \t Time Taken: 2 sec\n",
            "New learning rate = 0.0002000\n",
            "saving the latest model (epoch 2, total_steps 14)\n",
            "End of epoch 2 / 100 \t Time Taken: 0 sec\n",
            "New learning rate = 0.0002000\n",
            "saving the latest model (epoch 3, total_steps 21)\n",
            "End of epoch 3 / 100 \t Time Taken: 0 sec\n",
            "New learning rate = 0.0002000\n",
            "saving the latest model (epoch 4, total_steps 28)\n",
            "End of epoch 4 / 100 \t Time Taken: 1 sec\n",
            "New learning rate = 0.0002000\n",
            "saving the latest model (epoch 5, total_steps 35)\n",
            "End of epoch 5 / 100 \t Time Taken: 1 sec\n",
            "New learning rate = 0.0002000\n",
            "saving the latest model (epoch 6, total_steps 42)\n",
            "End of epoch 6 / 100 \t Time Taken: 0 sec\n",
            "New learning rate = 0.0002000\n",
            "saving the latest model (epoch 7, total_steps 49)\n",
            "End of epoch 7 / 100 \t Time Taken: 0 sec\n",
            "New learning rate = 0.0002000\n",
            "saving the latest model (epoch 8, total_steps 56)\n",
            "End of epoch 8 / 100 \t Time Taken: 0 sec\n",
            "New learning rate = 0.0002000\n",
            "saving the latest model (epoch 9, total_steps 63)\n",
            "End of epoch 9 / 100 \t Time Taken: 0 sec\n",
            "New learning rate = 0.0002000\n",
            "saving the latest model (epoch 10, total_steps 70)\n",
            "End of epoch 10 / 100 \t Time Taken: 0 sec\n",
            "New learning rate = 0.0002000\n",
            "saving the latest model (epoch 11, total_steps 77)\n",
            "End of epoch 11 / 100 \t Time Taken: 0 sec\n",
            "New learning rate = 0.0002000\n",
            "saving the latest model (epoch 12, total_steps 84)\n",
            "End of epoch 12 / 100 \t Time Taken: 0 sec\n",
            "New learning rate = 0.0002000\n",
            "saving the latest model (epoch 13, total_steps 91)\n",
            "End of epoch 13 / 100 \t Time Taken: 0 sec\n",
            "New learning rate = 0.0002000\n",
            "saving the latest model (epoch 14, total_steps 98)\n",
            "End of epoch 14 / 100 \t Time Taken: 0 sec\n",
            "New learning rate = 0.0002000\n",
            "saving the latest model (epoch 15, total_steps 105)\n",
            "End of epoch 15 / 100 \t Time Taken: 0 sec\n",
            "New learning rate = 0.0002000\n",
            "saving the latest model (epoch 16, total_steps 112)\n",
            "End of epoch 16 / 100 \t Time Taken: 1 sec\n",
            "New learning rate = 0.0002000\n",
            "saving the latest model (epoch 17, total_steps 119)\n",
            "End of epoch 17 / 100 \t Time Taken: 0 sec\n",
            "New learning rate = 0.0002000\n",
            "saving the latest model (epoch 18, total_steps 126)\n",
            "End of epoch 18 / 100 \t Time Taken: 0 sec\n",
            "New learning rate = 0.0002000\n",
            "saving the latest model (epoch 19, total_steps 133)\n",
            "End of epoch 19 / 100 \t Time Taken: 0 sec\n",
            "New learning rate = 0.0002000\n",
            "saving the latest model (epoch 20, total_steps 140)\n",
            "End of epoch 20 / 100 \t Time Taken: 0 sec\n",
            "New learning rate = 0.0002000\n",
            "saving the latest model (epoch 21, total_steps 147)\n",
            "End of epoch 21 / 100 \t Time Taken: 0 sec\n",
            "New learning rate = 0.0002000\n",
            "saving the latest model (epoch 22, total_steps 154)\n",
            "End of epoch 22 / 100 \t Time Taken: 0 sec\n",
            "New learning rate = 0.0002000\n",
            "saving the latest model (epoch 23, total_steps 161)\n",
            "End of epoch 23 / 100 \t Time Taken: 0 sec\n",
            "New learning rate = 0.0002000\n",
            "saving the latest model (epoch 24, total_steps 168)\n",
            "End of epoch 24 / 100 \t Time Taken: 0 sec\n",
            "New learning rate = 0.0002000\n",
            "saving the latest model (epoch 25, total_steps 175)\n",
            "End of epoch 25 / 100 \t Time Taken: 0 sec\n",
            "New learning rate = 0.0002000\n",
            "saving the latest model (epoch 26, total_steps 182)\n",
            "End of epoch 26 / 100 \t Time Taken: 0 sec\n",
            "New learning rate = 0.0002000\n",
            "saving the latest model (epoch 27, total_steps 189)\n",
            "End of epoch 27 / 100 \t Time Taken: 0 sec\n",
            "New learning rate = 0.0002000\n",
            "saving the latest model (epoch 28, total_steps 196)\n",
            "End of epoch 28 / 100 \t Time Taken: 0 sec\n",
            "New learning rate = 0.0002000\n",
            "saving the latest model (epoch 29, total_steps 203)\n",
            "End of epoch 29 / 100 \t Time Taken: 1 sec\n",
            "New learning rate = 0.0002000\n",
            "saving the latest model (epoch 30, total_steps 210)\n",
            "End of epoch 30 / 100 \t Time Taken: 0 sec\n",
            "New learning rate = 0.0002000\n",
            "saving the latest model (epoch 31, total_steps 217)\n",
            "End of epoch 31 / 100 \t Time Taken: 1 sec\n",
            "New learning rate = 0.0002000\n",
            "saving the latest model (epoch 32, total_steps 224)\n",
            "End of epoch 32 / 100 \t Time Taken: 0 sec\n",
            "New learning rate = 0.0002000\n",
            "saving the latest model (epoch 33, total_steps 231)\n",
            "End of epoch 33 / 100 \t Time Taken: 0 sec\n",
            "New learning rate = 0.0002000\n",
            "saving the latest model (epoch 34, total_steps 238)\n",
            "End of epoch 34 / 100 \t Time Taken: 0 sec\n",
            "New learning rate = 0.0002000\n",
            "saving the latest model (epoch 35, total_steps 245)\n",
            "End of epoch 35 / 100 \t Time Taken: 0 sec\n",
            "New learning rate = 0.0002000\n",
            "saving the latest model (epoch 36, total_steps 252)\n",
            "End of epoch 36 / 100 \t Time Taken: 0 sec\n",
            "New learning rate = 0.0002000\n",
            "saving the latest model (epoch 37, total_steps 259)\n",
            "End of epoch 37 / 100 \t Time Taken: 0 sec\n",
            "New learning rate = 0.0002000\n",
            "saving the latest model (epoch 38, total_steps 266)\n",
            "End of epoch 38 / 100 \t Time Taken: 0 sec\n",
            "New learning rate = 0.0002000\n",
            "saving the latest model (epoch 39, total_steps 273)\n",
            "End of epoch 39 / 100 \t Time Taken: 0 sec\n",
            "New learning rate = 0.0002000\n",
            "saving the latest model (epoch 40, total_steps 280)\n",
            "End of epoch 40 / 100 \t Time Taken: 0 sec\n",
            "New learning rate = 0.0002000\n",
            "saving the latest model (epoch 41, total_steps 287)\n",
            "End of epoch 41 / 100 \t Time Taken: 1 sec\n",
            "New learning rate = 0.0002000\n",
            "saving the latest model (epoch 42, total_steps 294)\n",
            "End of epoch 42 / 100 \t Time Taken: 1 sec\n",
            "New learning rate = 0.0002000\n",
            "saving the latest model (epoch 43, total_steps 301)\n",
            "End of epoch 43 / 100 \t Time Taken: 1 sec\n",
            "New learning rate = 0.0002000\n",
            "saving the latest model (epoch 44, total_steps 308)\n",
            "End of epoch 44 / 100 \t Time Taken: 0 sec\n",
            "New learning rate = 0.0002000\n",
            "saving the latest model (epoch 45, total_steps 315)\n",
            "End of epoch 45 / 100 \t Time Taken: 0 sec\n",
            "New learning rate = 0.0002000\n",
            "saving the latest model (epoch 46, total_steps 322)\n",
            "End of epoch 46 / 100 \t Time Taken: 0 sec\n",
            "New learning rate = 0.0002000\n",
            "saving the latest model (epoch 47, total_steps 329)\n",
            "End of epoch 47 / 100 \t Time Taken: 0 sec\n",
            "New learning rate = 0.0002000\n",
            "saving the latest model (epoch 48, total_steps 336)\n",
            "End of epoch 48 / 100 \t Time Taken: 0 sec\n",
            "New learning rate = 0.0002000\n",
            "saving the latest model (epoch 49, total_steps 343)\n",
            "End of epoch 49 / 100 \t Time Taken: 0 sec\n",
            "New learning rate = 0.0001961\n",
            "saving the latest model (epoch 50, total_steps 350)\n",
            "End of epoch 50 / 100 \t Time Taken: 0 sec\n",
            "New learning rate = 0.0001922\n",
            "saving the latest model (epoch 51, total_steps 357)\n",
            "End of epoch 51 / 100 \t Time Taken: 0 sec\n",
            "New learning rate = 0.0001882\n",
            "saving the latest model (epoch 52, total_steps 364)\n",
            "End of epoch 52 / 100 \t Time Taken: 0 sec\n",
            "New learning rate = 0.0001843\n",
            "saving the latest model (epoch 53, total_steps 371)\n",
            "End of epoch 53 / 100 \t Time Taken: 0 sec\n",
            "New learning rate = 0.0001804\n",
            "saving the latest model (epoch 54, total_steps 378)\n",
            "End of epoch 54 / 100 \t Time Taken: 0 sec\n",
            "New learning rate = 0.0001765\n",
            "saving the latest model (epoch 55, total_steps 385)\n",
            "End of epoch 55 / 100 \t Time Taken: 1 sec\n",
            "New learning rate = 0.0001725\n",
            "saving the latest model (epoch 56, total_steps 392)\n",
            "End of epoch 56 / 100 \t Time Taken: 0 sec\n",
            "New learning rate = 0.0001686\n",
            "saving the latest model (epoch 57, total_steps 399)\n",
            "End of epoch 57 / 100 \t Time Taken: 0 sec\n",
            "New learning rate = 0.0001647\n",
            "saving the latest model (epoch 58, total_steps 406)\n",
            "End of epoch 58 / 100 \t Time Taken: 0 sec\n",
            "New learning rate = 0.0001608\n",
            "saving the latest model (epoch 59, total_steps 413)\n",
            "End of epoch 59 / 100 \t Time Taken: 0 sec\n",
            "New learning rate = 0.0001569\n",
            "saving the latest model (epoch 60, total_steps 420)\n",
            "End of epoch 60 / 100 \t Time Taken: 0 sec\n",
            "New learning rate = 0.0001529\n",
            "saving the latest model (epoch 61, total_steps 427)\n",
            "End of epoch 61 / 100 \t Time Taken: 0 sec\n",
            "New learning rate = 0.0001490\n",
            "saving the latest model (epoch 62, total_steps 434)\n",
            "End of epoch 62 / 100 \t Time Taken: 1 sec\n",
            "New learning rate = 0.0001451\n",
            "saving the latest model (epoch 63, total_steps 441)\n",
            "End of epoch 63 / 100 \t Time Taken: 0 sec\n",
            "New learning rate = 0.0001412\n",
            "saving the latest model (epoch 64, total_steps 448)\n",
            "End of epoch 64 / 100 \t Time Taken: 0 sec\n",
            "New learning rate = 0.0001373\n",
            "saving the latest model (epoch 65, total_steps 455)\n",
            "End of epoch 65 / 100 \t Time Taken: 0 sec\n",
            "New learning rate = 0.0001333\n",
            "saving the latest model (epoch 66, total_steps 462)\n",
            "End of epoch 66 / 100 \t Time Taken: 0 sec\n",
            "New learning rate = 0.0001294\n",
            "saving the latest model (epoch 67, total_steps 469)\n",
            "End of epoch 67 / 100 \t Time Taken: 0 sec\n",
            "New learning rate = 0.0001255\n",
            "saving the latest model (epoch 68, total_steps 476)\n",
            "End of epoch 68 / 100 \t Time Taken: 1 sec\n",
            "New learning rate = 0.0001216\n",
            "saving the latest model (epoch 69, total_steps 483)\n",
            "End of epoch 69 / 100 \t Time Taken: 0 sec\n",
            "New learning rate = 0.0001176\n",
            "saving the latest model (epoch 70, total_steps 490)\n",
            "End of epoch 70 / 100 \t Time Taken: 0 sec\n",
            "New learning rate = 0.0001137\n",
            "saving the latest model (epoch 71, total_steps 497)\n",
            "End of epoch 71 / 100 \t Time Taken: 0 sec\n",
            "New learning rate = 0.0001098\n",
            "saving the latest model (epoch 72, total_steps 504)\n",
            "End of epoch 72 / 100 \t Time Taken: 0 sec\n",
            "New learning rate = 0.0001059\n",
            "saving the latest model (epoch 73, total_steps 511)\n",
            "End of epoch 73 / 100 \t Time Taken: 0 sec\n",
            "New learning rate = 0.0001020\n",
            "saving the latest model (epoch 74, total_steps 518)\n",
            "End of epoch 74 / 100 \t Time Taken: 0 sec\n",
            "New learning rate = 0.0000980\n",
            "saving the latest model (epoch 75, total_steps 525)\n",
            "End of epoch 75 / 100 \t Time Taken: 0 sec\n",
            "New learning rate = 0.0000941\n",
            "saving the latest model (epoch 76, total_steps 532)\n",
            "End of epoch 76 / 100 \t Time Taken: 0 sec\n",
            "New learning rate = 0.0000902\n",
            "saving the latest model (epoch 77, total_steps 539)\n",
            "End of epoch 77 / 100 \t Time Taken: 0 sec\n",
            "New learning rate = 0.0000863\n",
            "saving the latest model (epoch 78, total_steps 546)\n",
            "End of epoch 78 / 100 \t Time Taken: 0 sec\n",
            "New learning rate = 0.0000824\n",
            "saving the latest model (epoch 79, total_steps 553)\n",
            "End of epoch 79 / 100 \t Time Taken: 0 sec\n",
            "New learning rate = 0.0000784\n",
            "saving the latest model (epoch 80, total_steps 560)\n",
            "End of epoch 80 / 100 \t Time Taken: 1 sec\n",
            "New learning rate = 0.0000745\n",
            "saving the latest model (epoch 81, total_steps 567)\n",
            "End of epoch 81 / 100 \t Time Taken: 1 sec\n",
            "New learning rate = 0.0000706\n",
            "saving the latest model (epoch 82, total_steps 574)\n",
            "End of epoch 82 / 100 \t Time Taken: 0 sec\n",
            "New learning rate = 0.0000667\n",
            "saving the latest model (epoch 83, total_steps 581)\n",
            "End of epoch 83 / 100 \t Time Taken: 0 sec\n",
            "New learning rate = 0.0000627\n",
            "saving the latest model (epoch 84, total_steps 588)\n",
            "End of epoch 84 / 100 \t Time Taken: 0 sec\n",
            "New learning rate = 0.0000588\n",
            "saving the latest model (epoch 85, total_steps 595)\n",
            "End of epoch 85 / 100 \t Time Taken: 0 sec\n",
            "New learning rate = 0.0000549\n",
            "saving the latest model (epoch 86, total_steps 602)\n",
            "End of epoch 86 / 100 \t Time Taken: 0 sec\n",
            "New learning rate = 0.0000510\n",
            "saving the latest model (epoch 87, total_steps 609)\n",
            "End of epoch 87 / 100 \t Time Taken: 0 sec\n",
            "New learning rate = 0.0000471\n",
            "saving the latest model (epoch 88, total_steps 616)\n",
            "End of epoch 88 / 100 \t Time Taken: 0 sec\n",
            "New learning rate = 0.0000431\n",
            "saving the latest model (epoch 89, total_steps 623)\n",
            "End of epoch 89 / 100 \t Time Taken: 0 sec\n",
            "New learning rate = 0.0000392\n",
            "saving the latest model (epoch 90, total_steps 630)\n",
            "End of epoch 90 / 100 \t Time Taken: 0 sec\n",
            "New learning rate = 0.0000353\n",
            "saving the latest model (epoch 91, total_steps 637)\n",
            "End of epoch 91 / 100 \t Time Taken: 0 sec\n",
            "New learning rate = 0.0000314\n",
            "saving the latest model (epoch 92, total_steps 644)\n",
            "End of epoch 92 / 100 \t Time Taken: 1 sec\n",
            "New learning rate = 0.0000275\n",
            "saving the latest model (epoch 93, total_steps 651)\n",
            "End of epoch 93 / 100 \t Time Taken: 1 sec\n",
            "New learning rate = 0.0000235\n",
            "saving the latest model (epoch 94, total_steps 658)\n",
            "End of epoch 94 / 100 \t Time Taken: 0 sec\n",
            "New learning rate = 0.0000196\n",
            "saving the latest model (epoch 95, total_steps 665)\n",
            "End of epoch 95 / 100 \t Time Taken: 0 sec\n",
            "New learning rate = 0.0000157\n",
            "saving the latest model (epoch 96, total_steps 672)\n",
            "End of epoch 96 / 100 \t Time Taken: 0 sec\n",
            "New learning rate = 0.0000118\n",
            "saving the latest model (epoch 97, total_steps 679)\n",
            "End of epoch 97 / 100 \t Time Taken: 0 sec\n",
            "New learning rate = 0.0000078\n",
            "saving the latest model (epoch 98, total_steps 686)\n",
            "End of epoch 98 / 100 \t Time Taken: 0 sec\n",
            "New learning rate = 0.0000039\n",
            "saving the latest model (epoch 99, total_steps 693)\n",
            "End of epoch 99 / 100 \t Time Taken: 0 sec\n",
            "New learning rate = 0.0000000\n",
            "saving the latest model (epoch 100, total_steps 700)\n",
            "End of epoch 100 / 100 \t Time Taken: 0 sec\n",
            "New learning rate = -0.0000039\n",
            "#training images = 7\n",
            "20240415-031222 TD_DAPI-Fibrillarin/resvit\n",
            "resvit_one\n",
            "Res-ViT-B_16\n",
            "pre_trained_path:  ./results/20240415-031222 TD_DAPI-Fibrillarin/art_pretain/latest_net_G.pth\n",
            "Residual CNN loaded\n",
            "./model/vit_checkpoint/imagenet21k/R50+ViT-B_16.npz\n",
            "load_pretrained: grid-size from 14 to 16\n",
            "load_pretrained: grid-size from 14 to 16\n",
            "initialization method [normal]\n",
            "model [ResViT_model] was created\n",
            "saving the latest model (epoch 1, total_steps 7)\n",
            "End of epoch 1 / 50 \t Time Taken: 4 sec\n",
            "New learning rate = 0.0010000\n",
            "saving the latest model (epoch 2, total_steps 14)\n",
            "End of epoch 2 / 50 \t Time Taken: 9 sec\n",
            "New learning rate = 0.0010000\n",
            "saving the latest model (epoch 3, total_steps 21)\n",
            "End of epoch 3 / 50 \t Time Taken: 4 sec\n",
            "New learning rate = 0.0010000\n",
            "saving the latest model (epoch 4, total_steps 28)\n",
            "End of epoch 4 / 50 \t Time Taken: 4 sec\n",
            "New learning rate = 0.0010000\n",
            "saving the latest model (epoch 5, total_steps 35)\n",
            "End of epoch 5 / 50 \t Time Taken: 6 sec\n",
            "New learning rate = 0.0010000\n",
            "saving the latest model (epoch 6, total_steps 42)\n",
            "End of epoch 6 / 50 \t Time Taken: 3 sec\n",
            "New learning rate = 0.0010000\n",
            "saving the latest model (epoch 7, total_steps 49)\n",
            "End of epoch 7 / 50 \t Time Taken: 9 sec\n",
            "New learning rate = 0.0010000\n",
            "saving the latest model (epoch 8, total_steps 56)\n",
            "End of epoch 8 / 50 \t Time Taken: 4 sec\n",
            "New learning rate = 0.0010000\n",
            "saving the latest model (epoch 9, total_steps 63)\n",
            "End of epoch 9 / 50 \t Time Taken: 5 sec\n",
            "New learning rate = 0.0010000\n",
            "saving the latest model (epoch 10, total_steps 70)\n",
            "End of epoch 10 / 50 \t Time Taken: 4 sec\n",
            "New learning rate = 0.0010000\n",
            "saving the latest model (epoch 11, total_steps 77)\n",
            "End of epoch 11 / 50 \t Time Taken: 3 sec\n",
            "New learning rate = 0.0010000\n",
            "saving the latest model (epoch 12, total_steps 84)\n",
            "End of epoch 12 / 50 \t Time Taken: 9 sec\n",
            "New learning rate = 0.0010000\n",
            "saving the latest model (epoch 13, total_steps 91)\n",
            "End of epoch 13 / 50 \t Time Taken: 4 sec\n",
            "New learning rate = 0.0010000\n",
            "saving the latest model (epoch 14, total_steps 98)\n",
            "End of epoch 14 / 50 \t Time Taken: 4 sec\n",
            "New learning rate = 0.0010000\n",
            "saving the latest model (epoch 15, total_steps 105)\n",
            "End of epoch 15 / 50 \t Time Taken: 4 sec\n",
            "New learning rate = 0.0010000\n",
            "saving the latest model (epoch 16, total_steps 112)\n",
            "End of epoch 16 / 50 \t Time Taken: 7 sec\n",
            "New learning rate = 0.0010000\n",
            "saving the latest model (epoch 17, total_steps 119)\n",
            "End of epoch 17 / 50 \t Time Taken: 4 sec\n",
            "New learning rate = 0.0010000\n",
            "saving the latest model (epoch 18, total_steps 126)\n",
            "End of epoch 18 / 50 \t Time Taken: 9 sec\n",
            "New learning rate = 0.0010000\n",
            "saving the latest model (epoch 19, total_steps 133)\n",
            "End of epoch 19 / 50 \t Time Taken: 4 sec\n",
            "New learning rate = 0.0010000\n",
            "saving the latest model (epoch 20, total_steps 140)\n",
            "End of epoch 20 / 50 \t Time Taken: 4 sec\n",
            "New learning rate = 0.0010000\n",
            "saving the latest model (epoch 21, total_steps 147)\n",
            "End of epoch 21 / 50 \t Time Taken: 4 sec\n",
            "New learning rate = 0.0010000\n",
            "saving the latest model (epoch 22, total_steps 154)\n",
            "End of epoch 22 / 50 \t Time Taken: 4 sec\n",
            "New learning rate = 0.0010000\n",
            "saving the latest model (epoch 23, total_steps 161)\n",
            "End of epoch 23 / 50 \t Time Taken: 5 sec\n",
            "New learning rate = 0.0010000\n",
            "saving the latest model (epoch 24, total_steps 168)\n",
            "End of epoch 24 / 50 \t Time Taken: 9 sec\n",
            "New learning rate = 0.0009615\n",
            "saving the latest model (epoch 25, total_steps 175)\n",
            "End of epoch 25 / 50 \t Time Taken: 4 sec\n",
            "New learning rate = 0.0009231\n",
            "saving the latest model (epoch 26, total_steps 182)\n",
            "End of epoch 26 / 50 \t Time Taken: 4 sec\n",
            "New learning rate = 0.0008846\n",
            "saving the latest model (epoch 27, total_steps 189)\n",
            "End of epoch 27 / 50 \t Time Taken: 4 sec\n",
            "New learning rate = 0.0008462\n",
            "saving the latest model (epoch 28, total_steps 196)\n",
            "End of epoch 28 / 50 \t Time Taken: 4 sec\n",
            "New learning rate = 0.0008077\n",
            "saving the latest model (epoch 29, total_steps 203)\n",
            "End of epoch 29 / 50 \t Time Taken: 9 sec\n",
            "New learning rate = 0.0007692\n",
            "saving the latest model (epoch 30, total_steps 210)\n",
            "End of epoch 30 / 50 \t Time Taken: 4 sec\n",
            "New learning rate = 0.0007308\n",
            "saving the latest model (epoch 31, total_steps 217)\n",
            "End of epoch 31 / 50 \t Time Taken: 4 sec\n",
            "New learning rate = 0.0006923\n",
            "saving the latest model (epoch 32, total_steps 224)\n",
            "End of epoch 32 / 50 \t Time Taken: 4 sec\n",
            "New learning rate = 0.0006538\n",
            "saving the latest model (epoch 33, total_steps 231)\n",
            "End of epoch 33 / 50 \t Time Taken: 4 sec\n",
            "New learning rate = 0.0006154\n",
            "saving the latest model (epoch 34, total_steps 238)\n",
            "End of epoch 34 / 50 \t Time Taken: 9 sec\n",
            "New learning rate = 0.0005769\n",
            "saving the latest model (epoch 35, total_steps 245)\n",
            "End of epoch 35 / 50 \t Time Taken: 4 sec\n",
            "New learning rate = 0.0005385\n",
            "saving the latest model (epoch 36, total_steps 252)\n",
            "End of epoch 36 / 50 \t Time Taken: 4 sec\n",
            "New learning rate = 0.0005000\n",
            "saving the latest model (epoch 37, total_steps 259)\n",
            "End of epoch 37 / 50 \t Time Taken: 4 sec\n",
            "New learning rate = 0.0004615\n",
            "saving the latest model (epoch 38, total_steps 266)\n",
            "End of epoch 38 / 50 \t Time Taken: 4 sec\n",
            "New learning rate = 0.0004231\n",
            "saving the latest model (epoch 39, total_steps 273)\n",
            "End of epoch 39 / 50 \t Time Taken: 4 sec\n",
            "New learning rate = 0.0003846\n",
            "saving the latest model (epoch 40, total_steps 280)\n",
            "End of epoch 40 / 50 \t Time Taken: 9 sec\n",
            "New learning rate = 0.0003462\n",
            "saving the latest model (epoch 41, total_steps 287)\n",
            "End of epoch 41 / 50 \t Time Taken: 4 sec\n",
            "New learning rate = 0.0003077\n",
            "saving the latest model (epoch 42, total_steps 294)\n",
            "End of epoch 42 / 50 \t Time Taken: 4 sec\n",
            "New learning rate = 0.0002692\n",
            "saving the latest model (epoch 43, total_steps 301)\n",
            "End of epoch 43 / 50 \t Time Taken: 4 sec\n",
            "New learning rate = 0.0002308\n",
            "saving the latest model (epoch 44, total_steps 308)\n",
            "End of epoch 44 / 50 \t Time Taken: 6 sec\n",
            "New learning rate = 0.0001923\n",
            "saving the latest model (epoch 45, total_steps 315)\n",
            "End of epoch 45 / 50 \t Time Taken: 4 sec\n",
            "New learning rate = 0.0001538\n",
            "saving the latest model (epoch 46, total_steps 322)\n",
            "End of epoch 46 / 50 \t Time Taken: 9 sec\n",
            "New learning rate = 0.0001154\n",
            "saving the latest model (epoch 47, total_steps 329)\n",
            "End of epoch 47 / 50 \t Time Taken: 5 sec\n",
            "New learning rate = 0.0000769\n",
            "saving the latest model (epoch 48, total_steps 336)\n",
            "End of epoch 48 / 50 \t Time Taken: 4 sec\n",
            "New learning rate = 0.0000385\n",
            "saving the latest model (epoch 49, total_steps 343)\n",
            "End of epoch 49 / 50 \t Time Taken: 4 sec\n",
            "New learning rate = 0.0000000\n",
            "saving the latest model (epoch 50, total_steps 350)\n",
            "End of epoch 50 / 50 \t Time Taken: 3 sec\n",
            "New learning rate = -0.0000385\n",
            "resvit_one\n",
            "Res-ViT-B_16\n",
            "./model/vit_checkpoint/imagenet21k/R50+ViT-B_16.npz\n",
            "load_pretrained: grid-size from 14 to 16\n",
            "load_pretrained: grid-size from 14 to 16\n",
            "model [ResViT_model] was created\n",
            "0000: process image... 210622_gz_if12_XY11_4.tif\n",
            "0001: process image... 210622_gz_if12_XY11_1.tif\n",
            "resvit_one\n",
            "Res-ViT-B_16\n",
            "./model/vit_checkpoint/imagenet21k/R50+ViT-B_16.npz\n",
            "load_pretrained: grid-size from 14 to 16\n",
            "load_pretrained: grid-size from 14 to 16\n",
            "model [ResViT_model] was created\n",
            "0000: process image... 210622_gz_if12_XY11_6.tif\n",
            "0001: process image... 210622_gz_if12_XY11_3.tif\n",
            "0002: process image... 210622_gz_if12_XY11_4.tif\n",
            "0003: process image... 210622_gz_if12_XY11_2.tif\n",
            "0004: process image... 210622_gz_if12_XY11_10.tif\n",
            "0005: process image... 210622_gz_if12_XY11_7.tif\n",
            "0006: process image... 210622_gz_if12_XY11_8.tif\n",
            "0007: process image... 210622_gz_if12_XY11_9.tif\n",
            "0008: process image... 210622_gz_if12_XY11_1.tif\n",
            "0009: process image... 210622_gz_if12_XY11_5.tif\n"
          ]
        }
      ]
    }
  ]
}